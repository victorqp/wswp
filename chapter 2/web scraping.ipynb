{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request as urlreq\n",
    "import urllib.error as urlerr\n",
    "import urllib.parse as urlparse\n",
    "import urllib.robotparser as urlrp\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from common.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading:  http://example.webscraping.com/places/default/view/Argentina-11\n",
      "\n",
      "2,766,890 square kilometres\n",
      "41,343,201\n",
      "AR\n",
      "Argentina\n",
      "Buenos Aires\n",
      "SA\n",
      ".ar\n",
      "ARS\n",
      "Peso\n",
      "54\n",
      "@####@@@\n",
      "^([A-Z]\\d{4}[A-Z]{3})$\n",
      "es-AR,en,it,de,fr,gn\n",
      "CL BO UY PY BR \n"
     ]
    }
   ],
   "source": [
    "url  = \"http://example.webscraping.com/places/default/view/Argentina-11\"\n",
    "html = download(url)\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "trs = soup.find_all(attrs={'id':re.compile('places_.*__row')})\n",
    "for tr in trs:\n",
    "    td = tr.find(attrs={'class':'w2p_fw'})\n",
    "    value = td.text\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,766,890 square kilometres\n"
     ]
    }
   ],
   "source": [
    "import lxml.html\n",
    "\n",
    "tree = lxml.html.fromstring(html)\n",
    "td = tree.cssselect('tr#places_area__row > td.w2p_fw')[0]\n",
    "area = td.text_content()\n",
    "print(area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIELDS = ('area', 'population', 'iso', 'country', 'capital', 'continent',\n",
    "          'tld', 'currency_code', 'currency_name', 'phone', 'postal_code_format',\n",
    "          'postal_code_regex', 'languages', 'neighbours')\n",
    "\n",
    "def re_scraper(html):\n",
    "    results = {}\n",
    "    for field in FIELDS:\n",
    "        results[field] = re.search('<tr id=\"places_%s__row\">.*?<td class=\"w2p_fw\">(.*?)<\\/td>' % field, html.decode()).groups()[0]\n",
    "    \n",
    "    return results\n",
    "\n",
    "def bs_scraper(html):\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    results = {}\n",
    "    for field in FIELDS:\n",
    "        results[field] = soup.find('table').find('tr', id='places_%s__row' % field).find(\n",
    "                            'td', class_='w2p_fw').text\n",
    "        \n",
    "    return results\n",
    "\n",
    "def lxml_scraper(html):\n",
    "    tree = lxml.html.fromstring(html)\n",
    "    results = {}\n",
    "    for field in FIELDS:\n",
    "        results[field] = tree.cssselect('table > tr#places_%s__row > td.w2p_fw' %\n",
    "                                      field)[0].text_content()\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular expressions: 1.61 seconds\n",
      "BeautifulSoup: 10.67 seconds\n",
      "Lxml: 2.07 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "NUM_ITERATIONS = 1000\n",
    "\n",
    "for name, scraper in [('Regular expressions', re_scraper),\n",
    "                      ('BeautifulSoup', bs_scraper),\n",
    "                      ('Lxml', lxml_scraper)]:\n",
    "    start = time.time()\n",
    "    for i in range(NUM_ITERATIONS):\n",
    "        if scraper == re_scraper:\n",
    "            re.purge()\n",
    "        result = scraper(html)\n",
    "        assert(result['area'] == '2,766,890 square kilometres')\n",
    "    end = time.time()\n",
    "    print(\"%s: %.2f seconds\" % (name, end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_callback(url, html):\n",
    "    if re.search('/view/', url):\n",
    "        tree = lxml.html.fromstring(html)\n",
    "        row = [tree.cssselect('table > tr#places_{}__row > td.w2p_fw'.format(field))[0].text_content() for field in FIELDS]\n",
    "        print(url, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv \n",
    "\n",
    "class ScrapeCallback:\n",
    "    def __init__(self):\n",
    "        self.writer = csv.writer(open('countries.csv', 'w'))\n",
    "        self.fields = ('area', 'population', 'iso', 'country', 'capital', 'continent', 'tld', 'currency_code', 'currency_name', 'phone', 'postal_code_format', 'postal_code_regex', 'languages', 'neighbours')\n",
    "        self.writer.writerow(self.fields)\n",
    "\n",
    "    def __call__(self, url, html):\n",
    "        if re.search('/view/', url):\n",
    "            tree = lxml.html.fromstring(html)\n",
    "            row = []\n",
    "            for field in self.fields:\n",
    "                row.append(tree.cssselect('table > tr#places_{}__row > td.w2p_fw'.format(field))[0].text_content())\n",
    "            self.writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def link_crawler(seed_url, link_regex, max_depth=2, scrape_callback=None):\n",
    "    crawl_queue = [seed_url]\n",
    "    seen = {seed_url:0}\n",
    "    throttle = Throttle(3)\n",
    "    user_agent = 'victor'\n",
    "    rp = urlrp.RobotFileParser()\n",
    "    rp.set_url(\"http://example.webscraping.com/robots.txt\")\n",
    "    rp.read()\n",
    "    while crawl_queue:\n",
    "        url = crawl_queue.pop()\n",
    "        depth = seen[url]\n",
    "        if rp.can_fetch(user_agent, url):\n",
    "            throttle.wait(url)\n",
    "            html = download(url, user_agent)\n",
    "            if scrape_callback:\n",
    "                scrape_callback(url, html)\n",
    "            if depth != max_depth:\n",
    "                for link in get_links(html.decode()):\n",
    "                    # skip all login pages\n",
    "                    if re.search('login|register', link):\n",
    "                        continue\n",
    "                    if re.search(link_regex, link):\n",
    "                        # form absolute link\n",
    "                        link = urlparse.urljoin(seed_url, link)\n",
    "                        # check if this link is already seen\n",
    "                        if link not in seen:\n",
    "                            seen[link] = depth + 1\n",
    "                            crawl_queue.append(link)\n",
    "        else:\n",
    "            print('blocked by robots.txt, ', url)\n",
    "                    \n",
    "    return seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading:  http://example.webscraping.com\n",
      "Downloading:  http://example.webscraping.com/places/default/index/1\n",
      "Downloading:  http://example.webscraping.com/places/default/index/2\n",
      "Downloading:  http://example.webscraping.com/places/default/index/0\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Barbados-20\n",
      "http://example.webscraping.com/places/default/view/Barbados-20 ['431 square kilometres', '285,653', 'BB', 'Barbados', 'Bridgetown', 'NA', '.bb', 'BBD', 'Dollar', '+1-246', 'BB#####', '^(?:BB)*(\\\\d{5})$', 'en-BB', ' ']\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Bangladesh-19\n",
      "http://example.webscraping.com/places/default/view/Bangladesh-19 ['144,000 square kilometres', '156,118,464', 'BD', 'Bangladesh', 'Dhaka', 'AS', '.bd', 'BDT', 'Taka', '880', '####', '^(\\\\d{4})$', 'bn-BD,en', 'MM IN ']\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Bahrain-18\n",
      "http://example.webscraping.com/places/default/view/Bahrain-18 ['665 square kilometres', '738,004', 'BH', 'Bahrain', 'Manama', 'AS', '.bh', 'BHD', 'Dinar', '973', '####|###', '^(\\\\d{3}\\\\d?)$', 'ar-BH,en,fa,ur', ' ']\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Bahamas-17\n",
      "http://example.webscraping.com/places/default/view/Bahamas-17 ['13,940 square kilometres', '301,790', 'BS', 'Bahamas', 'Nassau', 'NA', '.bs', 'BSD', 'Dollar', '+1-242', '', '', 'en-BS', ' ']\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Azerbaijan-16\n",
      "http://example.webscraping.com/places/default/view/Azerbaijan-16 ['86,600 square kilometres', '8,303,512', 'AZ', 'Azerbaijan', 'Baku', 'AS', '.az', 'AZN', 'Manat', '994', 'AZ ####', '^(?:AZ)*(\\\\d{4})$', 'az,ru,hy', 'GE IR AM TR RU ']\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Austria-15\n",
      "http://example.webscraping.com/places/default/view/Austria-15 ['83,858 square kilometres', '8,205,000', 'AT', 'Austria', 'Vienna', 'EU', '.at', 'EUR', 'Euro', '43', '####', '^(\\\\d{4})$', 'de-AT,hr,hu,sl', 'CH DE HU SK CZ IT SI LI ']\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Australia-14\n",
      "http://example.webscraping.com/places/default/view/Australia-14 ['7,686,850 square kilometres', '21,515,754', 'AU', 'Australia', 'Canberra', 'OC', '.au', 'AUD', 'Dollar', '61', '####', '^(\\\\d{4})$', 'en-AU', ' ']\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Aruba-13\n",
      "http://example.webscraping.com/places/default/view/Aruba-13 ['193 square kilometres', '71,566', 'AW', 'Aruba', 'Oranjestad', 'NA', '.aw', 'AWG', 'Guilder', '297', '', '', 'nl-AW,es,en', ' ']\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Armenia-12\n",
      "http://example.webscraping.com/places/default/view/Armenia-12 ['29,800 square kilometres', '2,968,000', 'AM', 'Armenia', 'Yerevan', 'AS', '.am', 'AMD', 'Dram', '374', '######', '^(\\\\d{6})$', 'hy', 'GE IR AZ TR ']\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Argentina-11\n",
      "http://example.webscraping.com/places/default/view/Argentina-11 ['2,766,890 square kilometres', '41,343,201', 'AR', 'Argentina', 'Buenos Aires', 'SA', '.ar', 'ARS', 'Peso', '54', '@####@@@', '^([A-Z]\\\\d{4}[A-Z]{3})$', 'es-AR,en,it,de,fr,gn', 'CL BO UY PY BR ']\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Antigua-and-Barbuda-10\n",
      "http://example.webscraping.com/places/default/view/Antigua-and-Barbuda-10 ['443 square kilometres', '86,754', 'AG', 'Antigua and Barbuda', \"St. John's\", 'NA', '.ag', 'XCD', 'Dollar', '+1-268', '', '', 'en-AG', ' ']\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Antarctica-9\n",
      "http://example.webscraping.com/places/default/view/Antarctica-9 ['14,000,000 square kilometres', '0', 'AQ', 'Antarctica', '', 'AN', '.aq', '', '', '', '', '', '', ' ']\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Anguilla-8\n",
      "http://example.webscraping.com/places/default/view/Anguilla-8 ['102 square kilometres', '13,254', 'AI', 'Anguilla', 'The Valley', 'NA', '.ai', 'XCD', 'Dollar', '+1-264', '', '', 'en-AI', ' ']\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Angola-7\n",
      "http://example.webscraping.com/places/default/view/Angola-7 ['1,246,700 square kilometres', '13,068,161', 'AO', 'Angola', 'Luanda', 'AF', '.ao', 'AOA', 'Kwanza', '244', '', '', 'pt-AO', 'CD NA ZM CG ']\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Andorra-6\n",
      "http://example.webscraping.com/places/default/view/Andorra-6 ['468 square kilometres', '84,000', 'AD', 'Andorra', 'Andorra la Vella', 'EU', '.ad', 'EUR', 'Euro', '376', 'AD###', '^(?:AD)*(\\\\d{3})$', 'ca', 'ES FR ']\n",
      "Downloading:  http://example.webscraping.com/places/default/view/American-Samoa-5\n",
      "http://example.webscraping.com/places/default/view/American-Samoa-5 ['199 square kilometres', '57,881', 'AS', 'American Samoa', 'Pago Pago', 'OC', '.as', 'USD', 'Dollar', '+1-684', '', '', 'en-AS,sm,to', ' ']\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Algeria-4\n",
      "http://example.webscraping.com/places/default/view/Algeria-4 ['2,381,740 square kilometres', '34,586,184', 'DZ', 'Algeria', 'Algiers', 'AF', '.dz', 'DZD', 'Dinar', '213', '#####', '^(\\\\d{5})$', 'ar-DZ', 'NE EH LY MR TN MA ML ']\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Albania-3\n",
      "http://example.webscraping.com/places/default/view/Albania-3 ['28,748 square kilometres', '2,986,952', 'AL', 'Albania', 'Tirana', 'EU', '.al', 'ALL', 'Lek', '355', '', '', 'sq,el', 'MK GR CS ME RS XK ']\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Aland-Islands-2\n",
      "http://example.webscraping.com/places/default/view/Aland-Islands-2 ['1,580 square kilometres', '26,711', 'AX', 'Aland Islands', 'Mariehamn', 'EU', '.ax', 'EUR', 'Euro', '+358-18', '#####', '^(?:FI)*(\\\\d{5})$', 'sv-AX', ' ']\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Afghanistan-1\n",
      "http://example.webscraping.com/places/default/view/Afghanistan-1 ['647,500 square kilometres', '29,121,286', 'AF', 'Afghanistan', 'Kabul', 'AS', '.af', 'AFN', 'Afghani', '93', '', '', 'fa-AF,ps,uz-AF,tk', 'TM CN IR TJ PK UZ ']\n"
     ]
    }
   ],
   "source": [
    "all_links = link_crawler('http://example.webscraping.com', '/(index|view)/', scrape_callback=scrape_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading:  http://example.webscraping.com\n",
      "Downloading:  http://example.webscraping.com/places/default/index/1\n",
      "Downloading:  http://example.webscraping.com/places/default/index/2\n",
      "Downloading:  http://example.webscraping.com/places/default/index/0\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Barbados-20\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Bangladesh-19\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Bahrain-18\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Bahamas-17\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Azerbaijan-16\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Austria-15\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Australia-14\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Aruba-13\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Armenia-12\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Argentina-11\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Antigua-and-Barbuda-10\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Antarctica-9\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Anguilla-8\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Angola-7\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Andorra-6\n",
      "Downloading:  http://example.webscraping.com/places/default/view/American-Samoa-5\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Algeria-4\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Albania-3\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Aland-Islands-2\n",
      "Downloading:  http://example.webscraping.com/places/default/view/Afghanistan-1\n"
     ]
    }
   ],
   "source": [
    "all_links = link_crawler('http://example.webscraping.com', '/(index|view)/', scrape_callback=ScrapeCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
